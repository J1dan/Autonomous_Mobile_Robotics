{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autonomous_Mobile_Robotics Segmentation task 1\n",
    "* Usage\n",
    "\n",
    "Run the cell below first to initialize the libraries required and perform ground segmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34720, 4)\n",
      "Estimated number of clusters: 122\n",
      "Estimated number of noise points: 148\n",
      "shape of points = (34572, 5)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "import numpy as np \n",
    "import sklearn.cluster\n",
    "from sklearn import metrics\n",
    "\n",
    "# sys.path.append(str(pathlib.Path('task1_lidar_cls.ipynb').parent.parent))\n",
    "from libraries.clustering import clustering\n",
    "from libraries.ground_segmentation import ground_segmentation\n",
    "from libraries.visualization import vis \n",
    "from libraries.BoundingBoxExtraction import ExtractBBox\n",
    "\n",
    "file_data = np.fromfile('/home/jidan/Documents/me5413/1_lidar/lidar_data/frame2.pcd.bin', dtype=np.float32)\n",
    "points = file_data.reshape((-1, 5))[:, :4]\n",
    "print(np.shape(points))\n",
    "# Points: (x, y, z, intensity)\n",
    "\n",
    "GROUND_SEGMENTATION = True\n",
    "if GROUND_SEGMENTATION:\n",
    "    ground_cloud,segmented_cloud, index_ground, index_segmented = ground_segmentation(points[:,0:3], 'brutal')\n",
    "\n",
    "x = points[:, 0]  # x position of point\n",
    "y = points[:, 1]  # y position of point\n",
    "z = points[:, 2]  # z position of point\n",
    "r = points[:, 3]  # reflectance value of point\n",
    "d = np.sqrt(x ** 2 + y ** 2)  # Map Distance from sensor\n",
    "degr = np.degrees(np.arctan(z / d))\n",
    " \n",
    "vals = 'height'\n",
    "if vals == \"height\":\n",
    "    col = z\n",
    "else:\n",
    "    col = d\n",
    "\n",
    "#Clustering\n",
    "method = 'dbscan'  #Options: 'dbscan','kmeans','optics','meanshift','AgglomerativeClustering', 'birch'\n",
    "labels = clustering(segmented_cloud, method)\n",
    "labels += 1\n",
    "points = np.insert(points,4,0,axis = 1)\n",
    "points[index_ground, 4] = 1\n",
    "points[index_segmented, 4] = labels\n",
    "#Noise removal\n",
    "points = points[points[:,4] > 0]\n",
    "\n",
    "#Bounding Box Extraction\n",
    "bboxes = ExtractBBox(segmented_cloud, labels)\n",
    "\n",
    "#Visualization with ground points\n",
    "vis(points[:,0:3],points[:,4])\n",
    "#Visualization with ground points\n",
    "segmented_cloud = np.insert(segmented_cloud,3,0,axis = 1)\n",
    "segmented_cloud[:,3] = labels\n",
    "segmented_cloud = segmented_cloud[segmented_cloud[:,3] > 0]\n",
    "vis(segmented_cloud[:,0:3],segmented_cloud[:,3])\n",
    "\n",
    "#Data saving\n",
    "print(f\"shape of points = {np.shape(points)}\")\n",
    "\n",
    "\n",
    "# with open('lidar_clustering.json', 'w') as f:\n",
    "#     json.dump(points, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2013534c70eb131bc1ef82df7b2a81a82658ec77093eef0bf00387f699b3e2a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
