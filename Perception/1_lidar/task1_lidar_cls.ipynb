{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34720, 4)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "import numpy as np \n",
    "import open3d as o3d\n",
    "import sklearn.cluster\n",
    "from sklearn import metrics\n",
    "\n",
    "file_data = np.fromfile('/home/jidan/Documents/me5413/1_lidar/lidar_data/frame2.pcd.bin', dtype=np.float32)\n",
    "points = file_data.reshape((-1, 5))[:, :4]\n",
    "print(np.shape(points))\n",
    "# Points: (x, y, z, intensity)\n",
    "\n",
    "def ground_segmentation(data):\n",
    "    # 作业1\n",
    "    # 屏蔽开始\n",
    "    #初始化数据\n",
    "    idx_segmented = []\n",
    "    segmented_cloud = []\n",
    "    iters = 100   #最大迭代次数  000002.bin：10\n",
    "    sigma = 0.4     #数据和模型之间可接受的最大差值   000002.bin：0.5   000001.bin: 0.2  000000.bin: 0.15  002979.bin：0.15  004443.bin：0.4\n",
    "    ##最好模型的参数估计和内点数目,平面表达方程为   aX + bY + cZ +D= 0\n",
    "    best_a = 0\n",
    "    best_b = 0\n",
    "    best_c = 0\n",
    "    best_d = 0\n",
    "    pretotal = 0 #上一次inline的点数\n",
    "    #希望的到正确模型的概率\n",
    "    P = 0.99\n",
    "    n = len(data)    #点的数目\n",
    "    outline_ratio = 0.6   #e :outline_ratio   000002.bin：0.6    000001.bin: 0.5  000000.bin: 0.6   002979.bin：0.6\n",
    "    for i in range(iters):\n",
    "        ground_cloud = []\n",
    "        idx_ground = []\n",
    "        #step1 选择可以估计出模型的最小数据集，对于平面拟合来说，就是三个点\n",
    "        sample_index = random.sample(range(n),3)    #重数据集中随机选取3个点\n",
    "        point1 = data[sample_index[0]]\n",
    "        point2 = data[sample_index[1]]\n",
    "        point3 = data[sample_index[2]]\n",
    "        #step2 求解模型\n",
    "        ##先求解法向量\n",
    "        point1_2 = (point1-point2)      #向量 poin1 -> point2\n",
    "        point1_3 = (point1-point3)      #向量 poin1 -> point3\n",
    "        N = np.cross(point1_3,point1_2)            #向量叉乘求解 平面法向量\n",
    "        ##slove model 求解模型的a,b,c,d\n",
    "        a = N[0]\n",
    "        b = N[1]\n",
    "        c = N[2]\n",
    "        d = -N.dot(point1)\n",
    "        #step3 将所有数据带入模型，计算出“内点”的数目；(累加在一定误差范围内的适合当前迭代推出模型的数据)\n",
    "        total_inlier = 0\n",
    "        pointn_1 = (data - point1)    #sample（三点）外的点 与 sample内的三点其中一点 所构成的向量\n",
    "        distance = abs(pointn_1.dot(N))/ np.linalg.norm(N)     #求距离\n",
    "        ##使用距离判断inline\n",
    "        idx_ground = (distance <= sigma)\n",
    "        total_inlier = np.sum(idx_ground == True)    #统计inline得点数\n",
    "        ##判断当前的模型是否比之前估算的模型\n",
    "        if total_inlier > pretotal:                                           #     log(1 - p)\n",
    "            iters = math.log(1 - P) / math.log(1 - pow(total_inlier / n, 3))  #N = ------------\n",
    "            pretotal = total_inlier                                               #log(1-[(1-e)**s])\n",
    "            #获取最好得 abcd 模型参数\n",
    "            best_a = a\n",
    "            best_b = b\n",
    "            best_c = c\n",
    "            best_d = d\n",
    "\n",
    "        # 判断是否当前模型已经符合超过 inline_ratio\n",
    "        if total_inlier > n*(1-outline_ratio):\n",
    "            break\n",
    "    print(\"iters = %f\" %iters)\n",
    "    #提取分割后得点\n",
    "    idx_segmented = np.logical_not(idx_ground)\n",
    "    ground_cloud = data[idx_ground]\n",
    "    segmented_cloud = data[idx_segmented]\n",
    "    return ground_cloud,segmented_cloud,idx_ground,idx_segmented\n",
    "\n",
    "def clustering(points, method):\n",
    "    if method == 'dbscan':\n",
    "        db = sklearn.cluster.DBSCAN(eps=1.8, min_samples=20).fit(points)\n",
    "        labels_db = db.labels_\n",
    "\n",
    "        # Number of clusters in labels, ignoring noise if present.\n",
    "        n_clusters_ = len(set(labels_db)) - (1 if -1 in labels_db else 0)\n",
    "        n_noise_ = list(labels_db).count(-1)\n",
    "\n",
    "        print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "        print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "        return labels_db\n",
    "\n",
    "    if method == 'kmeans':\n",
    "        kmeans = sklearn.cluster.KMeans(n_clusters=70, random_state=0, n_init=\"auto\").fit(points)\n",
    "        labels_km = kmeans.labels_\n",
    "        return labels_km\n",
    "\n",
    "    if method == 'meanshift':\n",
    "        # The following bandwidth can be automatically detected using\n",
    "        bandwidth = sklearn.cluster.estimate_bandwidth(points, quantile=0.1, n_samples=500)\n",
    "\n",
    "        ms = sklearn.cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "        ms.fit(points)\n",
    "        labels_ms = ms.labels_\n",
    "        cluster_centers = ms.cluster_centers_\n",
    "\n",
    "        labels_unique = np.unique(labels_ms)\n",
    "        n_clusters_ = len(labels_unique)\n",
    "\n",
    "        print(\"number of estimated clusters : %d\" % n_clusters_)\n",
    "        return labels_ms\n",
    "\n",
    "    if method == 'optics':\n",
    "        clust = sklearn.cluster.OPTICS(min_samples=10, xi=0.05, min_cluster_size=0.05)\n",
    "\n",
    "        # Run the fit\n",
    "        clust.fit(points)\n",
    "        labels_op = clust.labels_\n",
    "        return labels_op\n",
    "\n",
    "#Visualization\n",
    "def vis(data,label):\n",
    "    '''\n",
    "    :param data: n*3的矩阵\n",
    "    :param label: n*1的矩阵\n",
    "    :return: 可视化\n",
    "    '''\n",
    "    data=data[:,:3]\n",
    "    labels=np.asarray(label)\n",
    "    max_label=labels.max()\n",
    "\n",
    "    # 颜色\n",
    "    colors = plt.get_cmap(\"tab20\")(labels / (max_label if max_label > 0 else 1))\n",
    "\n",
    "    pt1 = o3d.geometry.PointCloud()\n",
    "    pt1.points = o3d.utility.Vector3dVector(data.reshape(-1, 3))\n",
    "    pt1.colors=o3d.utility.Vector3dVector(colors[:, :3])\n",
    "\n",
    "    o3d.visualization.draw_geometries([pt1],'part of cloud',width=500,height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iters = 47.581142\n",
      "Estimated number of clusters: 43\n",
      "Estimated number of noise points: 2034\n",
      "points[index_ground] = [[-1.7265594e-03 -4.2208382e-01 -1.5841456e-02  1.5000000e+02]\n",
      " [-1.3560485e+01 -3.6877424e-01 -6.5695506e-01  1.5000000e+01]\n",
      " [-1.6296936e+01 -3.5155106e-01 -4.0475357e-01  9.0000000e+00]\n",
      " ...\n",
      " [-1.3675551e+01  3.8186893e-02  1.9219806e+00  7.4000000e+01]\n",
      " [-1.3668683e+01  4.2942531e-02  2.2456934e+00  7.0000000e+01]\n",
      " [-1.3653681e+01  4.7669467e-02  2.5725033e+00  4.2000000e+01]]\n",
      "points[index_ground] = [[-1.7265594e-03 -4.2208382e-01 -1.5841456e-02  1.5000000e+02]\n",
      " [-1.3560485e+01 -3.6877424e-01 -6.5695506e-01  1.5000000e+01]\n",
      " [-1.6296936e+01 -3.5155106e-01 -4.0475357e-01  9.0000000e+00]\n",
      " ...\n",
      " [-1.3675551e+01  3.8186893e-02  1.9219806e+00  7.4000000e+01]\n",
      " [-1.3668683e+01  4.2942531e-02  2.2456934e+00  7.0000000e+01]\n",
      " [-1.3653681e+01  4.7669467e-02  2.5725033e+00  4.2000000e+01]]\n",
      "points[index_segmented][:,3] = [150.  15.   9. ...  74.  70.  42.]\n",
      "labels = [0 1 2 ... 1 1 1]\n",
      "points[index_segmented][:,3] = [150.  15.   9. ...  74.  70.  42.]\n",
      "points[index_segmented][0:10] = [[-1.72655936e-03 -4.22083825e-01 -1.58414561e-02  1.50000000e+02]\n",
      " [-1.35604849e+01 -3.68774235e-01 -6.56955063e-01  1.50000000e+01]\n",
      " [-1.62969360e+01 -3.51551056e-01 -4.04753566e-01  9.00000000e+00]\n",
      " [-1.80335484e+01 -3.40054452e-01 -2.75519788e-02  3.80000000e+01]\n",
      " [-1.72655936e-03 -4.22083825e-01 -1.58414561e-02  6.90000000e+01]\n",
      " [-1.72655936e-03 -4.22083825e-01 -1.58414561e-02  1.20000000e+02]\n",
      " [-1.37366085e+01 -3.45690340e-01  9.35619950e-01  7.50000000e+01]\n",
      " [-1.37108011e+01 -3.40413749e-01  1.25415552e+00  8.80000000e+01]\n",
      " [-1.37110939e+01 -3.34976882e-01  1.57832110e+00  7.60000000e+01]\n",
      " [-1.36822472e+01 -3.32108587e-01  1.89776015e+00  7.00000000e+01]]\n",
      "segmented_cloud[0:10] = [[-1.72655936e-03 -4.22083825e-01 -1.58414561e-02  0.00000000e+00]\n",
      " [-1.35604849e+01 -3.68774235e-01 -6.56955063e-01  1.00000000e+00]\n",
      " [-1.62969360e+01 -3.51551056e-01 -4.04753566e-01  2.00000000e+00]\n",
      " [-1.80335484e+01 -3.40054452e-01 -2.75519788e-02  2.00000000e+00]\n",
      " [-1.72655936e-03 -4.22083825e-01 -1.58414561e-02  0.00000000e+00]\n",
      " [-1.72655936e-03 -4.22083825e-01 -1.58414561e-02  0.00000000e+00]\n",
      " [-1.37366085e+01 -3.45690340e-01  9.35619950e-01  1.00000000e+00]\n",
      " [-1.37108011e+01 -3.40413749e-01  1.25415552e+00  1.00000000e+00]\n",
      " [-1.37110939e+01 -3.34976882e-01  1.57832110e+00  1.00000000e+00]\n",
      " [-1.36822472e+01 -3.32108587e-01  1.89776015e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "x = points[:, 0]  # x position of point\n",
    "y = points[:, 1]  # y position of point\n",
    "z = points[:, 2]  # z position of point\n",
    "r = points[:, 3]  # reflectance value of point\n",
    "d = np.sqrt(x ** 2 + y ** 2)  # Map Distance from sensor\n",
    "degr = np.degrees(np.arctan(z / d))\n",
    " \n",
    "vals = 'height'\n",
    "if vals == \"height\":\n",
    "    col = z\n",
    "else:\n",
    "    col = d\n",
    "\n",
    "#Clustering\n",
    "ground_cloud,segmented_cloud, index_ground, index_segmented = ground_segmentation(points[:,0:3])\n",
    "method = 'dbscan'  #Options: 'dbsegmented_cloudan','kmeans','optics','meanshift'\n",
    "labels = clustering(segmented_cloud, method)\n",
    "\n",
    "#Visualization\n",
    "# vis(points[:,0:3],labels)\n",
    "vis(segmented_cloud,labels)\n",
    "\n",
    "#Data saving\n",
    "# points[:,3] = labels\n",
    "# points = points.tolist()\n",
    "\n",
    "print(f\"points[index_ground] = {(points[index_segmented])}\")\n",
    "tmp = points[index_ground]\n",
    "tmp[:,3] = -1\n",
    "points[index_ground] = tmp\n",
    "print(f\"points[index_ground] = {(points[index_segmented])}\")\n",
    "print(f\"points[index_segmented][:,3] = {(points[index_segmented][:,3])}\")\n",
    "print(f\"labels = {(labels)}\")\n",
    "\n",
    "points[index_segmented][:,3] = labels\n",
    "print(f\"points[index_segmented][:,3] = {(points[index_segmented][:,3])}\")\n",
    "\n",
    "vis(points[:,0:3],points[:,3])\n",
    "segmented_cloud = np.insert(segmented_cloud,3,np.transpose(labels),axis = 1)\n",
    "\n",
    "print(f\"points[index_segmented][0:10] = {points[index_segmented][0:10]}\")\n",
    "print(f\"segmented_cloud[0:10] = {segmented_cloud[0:10]}\")\n",
    "\n",
    "# segmented_cloud[:,3] = labels\n",
    "segmented_cloud = segmented_cloud.tolist()\n",
    "\n",
    "with open('lidar_clustering.json', 'w') as f:\n",
    "    json.dump(segmented_cloud, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2013534c70eb131bc1ef82df7b2a81a82658ec77093eef0bf00387f699b3e2a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
