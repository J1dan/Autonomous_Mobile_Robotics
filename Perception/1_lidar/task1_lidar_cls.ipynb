{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34720, 4)\n",
      "iters = 44.171657\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "import numpy as np \n",
    "import open3d as o3d\n",
    "import sklearn.cluster\n",
    "from sklearn import metrics\n",
    "\n",
    "# sys.path.append(str(pathlib.Path('task1_lidar_cls.ipynb').parent))\n",
    "# from libraries.clustering import clustering\n",
    "from libraries.ground_segmentation import ground_segmentation\n",
    "\n",
    "file_data = np.fromfile('/home/jidan/Documents/me5413/1_lidar/lidar_data/frame2.pcd.bin', dtype=np.float32)\n",
    "points = file_data.reshape((-1, 5))[:, :4]\n",
    "print(np.shape(points))\n",
    "# Points: (x, y, z, intensity)\n",
    "\n",
    "GROUND_SEGMENTATION = True\n",
    "if GROUND_SEGMENTATION:\n",
    "    ground_cloud,segmented_cloud, index_ground, index_segmented = ground_segmentation(points[:,0:3])\n",
    "\n",
    "def clustering(points, method):\n",
    "    if method == 'dbscan':\n",
    "        db = sklearn.cluster.DBSCAN(eps=2,min_samples=3).fit(points)#eps=1.8, min_samples=20\n",
    "        labels_db = db.labels_\n",
    "\n",
    "        # Number of clusters in labels, ignoring noise if present.\n",
    "        n_clusters_ = len(set(labels_db)) - (1 if -1 in labels_db else 0)\n",
    "        n_noise_ = list(labels_db).count(-1)\n",
    "\n",
    "        print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "        print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "        return labels_db\n",
    "\n",
    "    if method == 'kmeans':\n",
    "        kmeans = sklearn.cluster.KMeans(n_clusters=70, random_state=0, n_init=\"auto\").fit(points)\n",
    "        labels_km = kmeans.labels_\n",
    "        return labels_km\n",
    "\n",
    "    if method == 'meanshift':\n",
    "        # The following bandwidth can be automatically detected using\n",
    "        bandwidth = sklearn.cluster.estimate_bandwidth(points, quantile=0.1, n_samples=500)\n",
    "\n",
    "        ms = sklearn.cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "        ms.fit(points)\n",
    "        labels_ms = ms.labels_\n",
    "        cluster_centers = ms.cluster_centers_\n",
    "\n",
    "        labels_unique = np.unique(labels_ms)\n",
    "        n_clusters_ = len(labels_unique)\n",
    "\n",
    "        print(\"number of estimated clusters : %d\" % n_clusters_)\n",
    "        return labels_ms\n",
    "\n",
    "    if method == 'optics':\n",
    "        clust = sklearn.cluster.OPTICS(min_samples=6)\n",
    "\n",
    "        # Run the fit\n",
    "        clust.fit(points)\n",
    "        labels_op = clust.labels_[clust.ordering_]\n",
    "        return labels_op\n",
    "\n",
    "    if method == 'AgglomerativeClustering':\n",
    "        clustering = sklearn.cluster.AgglomerativeClustering(70).fit(points)\n",
    "        return clustering.labels_\n",
    "\n",
    "    if method == 'birch':\n",
    "        clustring = sklearn.cluster.Birch(n_clusters=None).fit(points)\n",
    "        labels_brc = clustring.predict(points)\n",
    "        return labels_brc\n",
    "\n",
    "#Visualization\n",
    "def vis(data,label):\n",
    "    '''\n",
    "    :param data: n*3 matrix\n",
    "    :param label: n*1 matrix\n",
    "    :return: visualization\n",
    "    '''\n",
    "    labels=np.asarray(label)\n",
    "    max_label=labels.max()\n",
    "\n",
    "    # 颜色\n",
    "    colors = plt.get_cmap(\"tab20\")(labels / (max_label if max_label > 0 else 1))\n",
    "    pt1 = o3d.geometry.PointCloud()\n",
    "    pt1.points = o3d.utility.Vector3dVector(data.reshape(-1, 3))\n",
    "    pt1.colors=o3d.utility.Vector3dVector(colors[:, :3])\n",
    "\n",
    "    o3d.visualization.draw_geometries([pt1],'part of cloud',width=500,height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f59d73eed30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jidan/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/jidan/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/jidan/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/jidan/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f59d716b310>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jidan/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/jidan/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/jidan/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/jidan/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of points = (34720, 5)\n"
     ]
    }
   ],
   "source": [
    "x = points[:, 0]  # x position of point\n",
    "y = points[:, 1]  # y position of point\n",
    "z = points[:, 2]  # z position of point\n",
    "r = points[:, 3]  # reflectance value of point\n",
    "d = np.sqrt(x ** 2 + y ** 2)  # Map Distance from sensor\n",
    "degr = np.degrees(np.arctan(z / d))\n",
    " \n",
    "vals = 'height'\n",
    "if vals == \"height\":\n",
    "    col = z\n",
    "else:\n",
    "    col = d\n",
    "\n",
    "#Clustering\n",
    "method = 'birch'  #Options: 'dbscan','kmeans','optics','meanshift','AgglomerativeClustering'\n",
    "labels = clustering(segmented_cloud, method)\n",
    "\n",
    "#Visualization\n",
    "vis(segmented_cloud,labels)\n",
    "\n",
    "#Data saving\n",
    "points = np.insert(points,3,0,axis = 1)\n",
    "print(f\"shape of points = {np.shape(points)}\")\n",
    "\n",
    "points[index_ground, 4] = 80\n",
    "\n",
    "points[index_segmented, 4] = labels\n",
    "\n",
    "vis(points[:,0:3],points[:,4])\n",
    "\n",
    "points = points.tolist()\n",
    "\n",
    "with open('lidar_clustering.json', 'w') as f:\n",
    "    json.dump(points, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2013534c70eb131bc1ef82df7b2a81a82658ec77093eef0bf00387f699b3e2a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
